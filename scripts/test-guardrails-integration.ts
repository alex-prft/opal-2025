#!/usr/bin/env npx ts-node\n\n/**\n * Comprehensive Guardrails Integration Test\n * \n * This script tests all components of the Supabase guardrails system\n * to ensure proper integration and functionality.\n */\n\nimport { \n  initializeGuardrails,\n  checkGuardrailsHealth,\n  secureSupabase,\n  configurationValidator,\n  auditSystem,\n  dataRetentionManager,\n  supabaseGuardrails,\n  isDatabaseAvailable\n} from '../src/lib/database';\n\ninterface TestResult {\n  test: string;\n  passed: boolean;\n  message: string;\n  duration: number;\n  details?: any;\n}\n\nclass GuardrailsIntegrationTest {\n  private results: TestResult[] = [];\n  \n  async runAllTests(): Promise<void> {\n    console.log('üß™ Starting OSA Supabase Guardrails Integration Tests\\n');\n    console.log('=' .repeat(60));\n    \n    // Basic connectivity tests\n    await this.testDatabaseConnectivity();\n    await this.testGuardrailsInitialization();\n    \n    // Core functionality tests\n    await this.testPIIDetection();\n    await this.testDataClassification();\n    await this.testSecureClientOperations();\n    await this.testValidationSystem();\n    await this.testAuditLogging();\n    await this.testDataRetention();\n    \n    // Integration tests\n    await this.testEndToEndWorkflow();\n    await this.testHealthMonitoring();\n    \n    // Performance tests\n    await this.testPerformanceImpact();\n    \n    // Generate report\n    this.generateReport();\n  }\n  \n  private async runTest<T>(\n    testName: string,\n    testFn: () => Promise<T>\n  ): Promise<T | null> {\n    const startTime = performance.now();\n    \n    try {\n      console.log(`\\nüîç Testing: ${testName}`);\n      \n      const result = await testFn();\n      const duration = performance.now() - startTime;\n      \n      this.results.push({\n        test: testName,\n        passed: true,\n        message: 'Test passed successfully',\n        duration: Math.round(duration),\n        details: typeof result === 'object' ? result : undefined\n      });\n      \n      console.log(`‚úÖ PASS (${Math.round(duration)}ms)`);\n      return result;\n      \n    } catch (error) {\n      const duration = performance.now() - startTime;\n      const message = error instanceof Error ? error.message : 'Unknown error';\n      \n      this.results.push({\n        test: testName,\n        passed: false,\n        message,\n        duration: Math.round(duration),\n        details: error instanceof Error ? { stack: error.stack } : undefined\n      });\n      \n      console.log(`‚ùå FAIL (${Math.round(duration)}ms): ${message}`);\n      return null;\n    }\n  }\n  \n  private async testDatabaseConnectivity(): Promise<void> {\n    await this.runTest('Database Connectivity', async () => {\n      const available = isDatabaseAvailable();\n      if (!available) {\n        throw new Error('Database is not available');\n      }\n      return { database_available: true };\n    });\n  }\n  \n  private async testGuardrailsInitialization(): Promise<void> {\n    await this.runTest('Guardrails Initialization', async () => {\n      await initializeGuardrails();\n      return { initialized: true };\n    });\n  }\n  \n  private async testPIIDetection(): Promise<void> {\n    await this.runTest('PII Detection System', async () => {\n      const testData = {\n        name: 'John Doe',\n        email: 'john.doe@example.com',\n        phone: '555-123-4567',\n        normal_field: 'This is safe data'\n      };\n      \n      const scanResult = await supabaseGuardrails.scanForPII(testData);\n      \n      if (!scanResult.hasPII) {\n        throw new Error('PII detection failed - should have detected PII');\n      }\n      \n      const expectedTypes = ['email', 'phone'];\n      const hasExpectedTypes = expectedTypes.every(type => \n        scanResult.detectedTypes.includes(type)\n      );\n      \n      if (!hasExpectedTypes) {\n        throw new Error(`Missing expected PII types. Found: ${scanResult.detectedTypes.join(', ')}`);\n      }\n      \n      return {\n        detected_types: scanResult.detectedTypes,\n        violation_count: scanResult.violations.length\n      };\n    });\n  }\n  \n  private async testDataClassification(): Promise<void> {\n    await this.runTest('Data Classification', async () => {\n      const testCases = [\n        { table: 'opal_configurations', expected: 'configuration' },\n        { table: 'session_states', expected: 'temporary' },\n        { table: 'anonymous_usage_metrics', expected: 'anonymous_metrics' },\n        { table: 'opal_workflow_executions', expected: 'metadata' }\n      ];\n      \n      const results = [];\n      \n      for (const testCase of testCases) {\n        const validation = await supabaseGuardrails.validateDataOperation(\n          testCase.table,\n          'read',\n          null\n        );\n        \n        results.push({\n          table: testCase.table,\n          expected: testCase.expected,\n          validation_passed: validation.allowed\n        });\n      }\n      \n      return { classification_tests: results };\n    });\n  }\n  \n  private async testSecureClientOperations(): Promise<void> {\n    await this.runTest('Secure Client Operations', async () => {\n      // Test valid configuration data\n      const validConfig = {\n        name: 'test-agent-' + Date.now(),\n        type: 'content',\n        configuration: {\n          model: 'gpt-4',\n          parameters: { creativity: 0.7 }\n        },\n        enabled: true\n      };\n      \n      // This should succeed\n      const result = await secureSupabase\n        .from('opal_agent_configs')\n        .insert(validConfig, { classification: 'configuration' });\n      \n      if (result.error) {\n        throw new Error(`Secure client operation failed: ${result.error.message}`);\n      }\n      \n      return {\n        operation: 'insert',\n        table: 'opal_agent_configs',\n        success: true\n      };\n    });\n  }\n  \n  private async testValidationSystem(): Promise<void> {\n    await this.runTest('Validation System', async () => {\n      // Test valid data\n      const validResult = await configurationValidator.validateOperation({\n        table: 'opal_configurations',\n        operation: 'write',\n        data: {\n          setting_key: 'test_setting',\n          setting_value: 'test_value'\n        }\n      });\n      \n      if (!validResult.allowed) {\n        throw new Error(`Valid data was rejected: ${validResult.reason}`);\n      }\n      \n      // Test PII data (should be rejected)\n      const piiResult = await configurationValidator.validateOperation({\n        table: 'opal_workflow_executions',\n        operation: 'write',\n        data: {\n          client_name: 'Test Client',\n          contact_email: 'test@example.com' // This should trigger PII detection\n        }\n      });\n      \n      if (piiResult.allowed) {\n        throw new Error('PII data was not rejected by validation system');\n      }\n      \n      return {\n        valid_data_test: validResult.allowed,\n        pii_data_test: !piiResult.allowed,\n        pii_rejection_reason: piiResult.reason\n      };\n    });\n  }\n  \n  private async testAuditLogging(): Promise<void> {\n    await this.runTest('Audit Logging System', async () => {\n      // Log a test event\n      await auditSystem.logEvent({\n        event_type: 'SYSTEM_EVENT',\n        details: {\n          test_event: 'integration_test',\n          timestamp: new Date().toISOString()\n        },\n        severity: 'low',\n        status: 'success'\n      });\n      \n      // Query recent events\n      const yesterday = new Date();\n      yesterday.setDate(yesterday.getDate() - 1);\n      \n      const { events, total } = await auditSystem.queryEvents({\n        event_types: ['SYSTEM_EVENT'],\n        date_range: {\n          start: yesterday,\n          end: new Date()\n        },\n        limit: 10\n      });\n      \n      return {\n        events_logged: total > 0,\n        recent_events: events.length,\n        total_events: total\n      };\n    });\n  }\n  \n  private async testDataRetention(): Promise<void> {\n    await this.runTest('Data Retention System', async () => {\n      // Get retention status\n      const retentionStatus = await dataRetentionManager.getRetentionStatus();\n      \n      if (retentionStatus.length === 0) {\n        throw new Error('No retention policies found');\n      }\n      \n      // Run a dry-run purge to test the system\n      const dryRunResult = await dataRetentionManager.executeRetentionPolicies(true);\n      \n      return {\n        policies_loaded: retentionStatus.length,\n        dry_run_executed: true,\n        total_records_would_affect: dryRunResult.totalRecordsAffected\n      };\n    });\n  }\n  \n  private async testEndToEndWorkflow(): Promise<void> {\n    await this.runTest('End-to-End Workflow', async () => {\n      const workflowId = `test-workflow-${Date.now()}`;\n      \n      // Step 1: Create a workflow execution record\n      const workflowData = {\n        session_id: `test-session-${Date.now()}`,\n        status: 'pending',\n        client_name: 'Integration Test Client',\n        industry: 'Technology',\n        triggered_by: 'integration_test'\n      };\n      \n      const insertResult = await secureSupabase\n        .from('opal_workflow_executions')\n        .insert(workflowData, { classification: 'metadata' });\n      \n      if (insertResult.error) {\n        throw new Error(`Workflow creation failed: ${insertResult.error.message}`);\n      }\n      \n      // Step 2: Update the workflow status\n      const updateResult = await secureSupabase\n        .from('opal_workflow_executions')\n        .update(\n          { status: 'completed', completed_at: new Date().toISOString() },\n          { classification: 'metadata' }\n        )\n        .eq('session_id', workflowData.session_id);\n      \n      if (updateResult.error) {\n        throw new Error(`Workflow update failed: ${updateResult.error.message}`);\n      }\n      \n      // Step 3: Query the workflow\n      const queryResult = await secureSupabase\n        .from('opal_workflow_executions')\n        .select('*', { classification: 'metadata' })\n        .eq('session_id', workflowData.session_id)\n        .single();\n      \n      if (queryResult.error) {\n        throw new Error(`Workflow query failed: ${queryResult.error.message}`);\n      }\n      \n      return {\n        workflow_created: true,\n        workflow_updated: true,\n        workflow_queried: true,\n        final_status: queryResult.data.status\n      };\n    });\n  }\n  \n  private async testHealthMonitoring(): Promise<void> {\n    await this.runTest('Health Monitoring', async () => {\n      const health = await checkGuardrailsHealth();\n      \n      if (health.status === 'critical') {\n        throw new Error(`System health is critical: ${JSON.stringify(health.checks)}`);\n      }\n      \n      return {\n        overall_status: health.status,\n        check_count: health.checks.length,\n        passed_checks: health.checks.filter(c => c.status === 'pass').length,\n        failed_checks: health.checks.filter(c => c.status === 'fail').length\n      };\n    });\n  }\n  \n  private async testPerformanceImpact(): Promise<void> {\n    await this.runTest('Performance Impact', async () => {\n      const operations = 50;\n      const startTime = performance.now();\n      \n      // Perform multiple operations to test performance\n      const promises = [];\n      \n      for (let i = 0; i < operations; i++) {\n        const operation = secureSupabase\n          .from('anonymous_usage_metrics')\n          .insert({\n            metric_type: 'performance_test',\n            aggregation_level: 'daily',\n            value: i,\n            timestamp: new Date().toISOString()\n          }, { classification: 'anonymous_metrics' });\n          \n        promises.push(operation);\n      }\n      \n      const results = await Promise.all(promises);\n      const duration = performance.now() - startTime;\n      \n      const errors = results.filter(r => r.error).length;\n      const avgTimePerOp = duration / operations;\n      \n      if (avgTimePerOp > 1000) { // More than 1 second per operation is too slow\n        throw new Error(`Performance degradation detected: ${avgTimePerOp}ms per operation`);\n      }\n      \n      return {\n        operations_count: operations,\n        total_duration_ms: Math.round(duration),\n        avg_time_per_operation_ms: Math.round(avgTimePerOp),\n        error_count: errors,\n        operations_per_second: Math.round(operations / (duration / 1000))\n      };\n    });\n  }\n  \n  private generateReport(): void {\n    console.log('\\n\\nüìä TEST REPORT\\n');\n    console.log('=' .repeat(60));\n    \n    const passed = this.results.filter(r => r.passed).length;\n    const failed = this.results.filter(r => !r.passed).length;\n    const totalDuration = this.results.reduce((sum, r) => sum + r.duration, 0);\n    \n    console.log(`Total Tests: ${this.results.length}`);\n    console.log(`Passed: ${passed} ‚úÖ`);\n    console.log(`Failed: ${failed} ${failed > 0 ? '‚ùå' : ''}`);\n    console.log(`Total Duration: ${Math.round(totalDuration)}ms`);\n    console.log(`Success Rate: ${Math.round((passed / this.results.length) * 100)}%`);\n    \n    if (failed > 0) {\n      console.log('\\n‚ùå FAILED TESTS:');\n      console.log('-'.repeat(40));\n      \n      this.results\n        .filter(r => !r.passed)\n        .forEach(result => {\n          console.log(`‚Ä¢ ${result.test}`);\n          console.log(`  Error: ${result.message}`);\n          console.log(`  Duration: ${result.duration}ms\\n`);\n        });\n    }\n    \n    console.log('\\nüìà PERFORMANCE SUMMARY:');\n    console.log('-'.repeat(40));\n    \n    this.results\n      .sort((a, b) => b.duration - a.duration)\n      .slice(0, 5)\n      .forEach(result => {\n        const status = result.passed ? '‚úÖ' : '‚ùå';\n        console.log(`${status} ${result.test}: ${result.duration}ms`);\n      });\n    \n    // Overall assessment\n    console.log('\\nüéØ OVERALL ASSESSMENT:');\n    console.log('-'.repeat(40));\n    \n    if (failed === 0) {\n      console.log('üéâ ALL TESTS PASSED! Guardrails system is fully operational.');\n    } else if (failed <= 2) {\n      console.log('‚ö†Ô∏è  MOSTLY FUNCTIONAL with minor issues. Review failed tests.');\n    } else {\n      console.log('üö® SIGNIFICANT ISSUES DETECTED. System may not be ready for production.');\n    }\n    \n    console.log(`\\nüìã Integration Status: ${failed === 0 ? 'READY' : 'NEEDS ATTENTION'}`);\n  }\n}\n\n// CLI execution\nasync function main() {\n  const test = new GuardrailsIntegrationTest();\n  \n  try {\n    await test.runAllTests();\n    process.exit(0);\n  } catch (error) {\n    console.error('\\nüí• Test execution failed:', error);\n    process.exit(1);\n  }\n}\n\nif (require.main === module) {\n  main();\n}\n\nexport { GuardrailsIntegrationTest };